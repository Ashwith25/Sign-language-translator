{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from keras.layers.normalization import layer_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers.normalization import layer_normalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test image directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'gestures\\train'\n",
    "test_path = r'gestures\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 755 images belonging to 5 classes.\n",
      "Found 755 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "76/76 [==============================] - 6s 55ms/step - loss: 2.7840 - accuracy: 0.9192 - val_loss: 0.2156 - val_accuracy: 0.9470\n",
      "Epoch 2/100\n",
      "76/76 [==============================] - 4s 51ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9510\n",
      "Epoch 3/100\n",
      "76/76 [==============================] - 4s 55ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9536\n",
      "Epoch 4/100\n",
      "76/76 [==============================] - 4s 46ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9550\n",
      "Epoch 5/100\n",
      "76/76 [==============================] - 3s 45ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9563\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation =\"relu\"))\n",
    "model.add(Dense(128, activation =\"relu\"))\n",
    "model.add(Dense(128, activation =\"relu\"))\n",
    "model.add(Dense(5, activation =\"softmax\")) # Change the number of classes to the number of gestures added\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "history2 = model.fit(train_batches, epochs=100, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: signForColor\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('signForBW') # For Ashwith's system\n",
    "# model.save('sign_model.h5') # For Manasi's system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 0.39209672808647156; accuracy of 89.99999761581421%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39209672808647156, 0.8999999761581421]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, labels = next(test_batches) \n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print('{0} of {1}; {2} of {3}%'\n",
    ".format(model.metrics_names[0], scores[0], model.metrics_names[1], scores[1]*100))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 0.08407296240329742; accuracy of 100.0%\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(test_batches)\n",
    "model = keras.models.load_model(\"signForBW\") # Change the model name accordingly\n",
    "# new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print('{0} of {1}; {2} of {3}%'\n",
    ".format(model.metrics_names[0], scores[0], model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 413,701\n",
      "Trainable params: 413,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels\n",
      "One\n",
      "A\n",
      "C\n",
      "D\n",
      "A\n",
      "D\n",
      "I Love You\n",
      "Two\n",
      "E\n",
      "One\n",
      "Actual labels\n",
      "One\n",
      "A\n",
      "C\n",
      "D\n",
      "A\n",
      "D\n",
      "I Love You\n",
      "Two\n",
      "E\n",
      "One\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(test_batches) \n",
    "\n",
    "word_dict = {0:'One', 1:'Two', 2:'Three', 3:'I Love You', 4:'Little'} # Sort it according to the folder names\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "print(\"Predicted labels\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)])\n",
    "    predicted_labels.append(word_dict[np.argmax(i)])\n",
    "    \n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)])\n",
    "    actual_labels.append(word_dict[np.argmax(i)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.9333333333333332\n",
      "Recall 0.9333333333333333\n",
      "f1_score 0.9199999999999999\n",
      "confusion_matrix: \n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 3 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Precision\", sk.metrics.precision_score(actual_labels, predicted_labels, average='macro'))\n",
    "print (\"Recall\", sk.metrics.recall_score(actual_labels, predicted_labels, average='macro'))\n",
    "print (\"f1_score\", sk.metrics.f1_score(actual_labels, predicted_labels, average='macro'))\n",
    "print (\"confusion_matrix: \")\n",
    "print (sk.metrics.confusion_matrix(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8876858e-01, 1.0727884e-02, 5.0357770e-04],\n",
       "       [2.1651026e-03, 9.9640560e-01, 1.4292375e-03],\n",
       "       [9.9556869e-01, 3.3518095e-03, 1.0795402e-03],\n",
       "       [5.9244330e-06, 1.7637222e-04, 9.9981779e-01],\n",
       "       [3.8885388e-05, 2.0312744e-03, 9.9792981e-01],\n",
       "       [4.3068114e-03, 9.9475753e-01, 9.3558541e-04],\n",
       "       [2.5023993e-03, 7.7351741e-03, 9.8976249e-01],\n",
       "       [9.9923503e-01, 4.6021870e-04, 3.0467054e-04],\n",
       "       [1.8225446e-02, 4.9001750e-01, 4.9175704e-01],\n",
       "       [9.7995055e-01, 1.9079464e-02, 9.6999458e-04]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbefc7fec24977a464f4b9c177a97fefd575b7fc826e54ce789a21be2d4f3465"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('signLanguage': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and Test image directory paths"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_path = r'D:\\gesture\\train'\n",
    "test_path = r'D:\\gesture\\test'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 629 images belonging to 3 classes.\n",
      "Found 413 images belonging to 3 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(3,activation =\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "history2 = model.fit(train_batches, epochs=100, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 6s 54ms/step - loss: 1.7751 - accuracy: 0.8394 - val_loss: 0.4647 - val_accuracy: 0.7918\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0568 - accuracy: 0.9889 - val_loss: 0.3920 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0169 - accuracy: 0.9984 - val_loss: 0.3041 - val_accuracy: 0.9153\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9080\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9104\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "history2.history"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [1.775146484375,\n",
       "  0.0567680187523365,\n",
       "  0.016947966068983078,\n",
       "  0.00819460116326809,\n",
       "  0.0055899121798574924],\n",
       " 'accuracy': [0.839427649974823,\n",
       "  0.9888712167739868,\n",
       "  0.998410165309906,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'val_loss': [0.46471813321113586,\n",
       "  0.39198121428489685,\n",
       "  0.30411002039909363,\n",
       "  0.32105693221092224,\n",
       "  0.31727659702301025],\n",
       " 'val_accuracy': [0.7917675375938416,\n",
       "  0.8571428656578064,\n",
       "  0.9152542352676392,\n",
       "  0.9079903364181519,\n",
       "  0.9104115962982178],\n",
       " 'lr': [0.001, 0.001, 0.001, 0.001, 0.0005]}"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving our model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "model.save('sign_model.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "imgs, labels = next(test_batches) \n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print('{0} of {1}; {2} of {3}%'\n",
    ".format(model.metrics_names[0], scores[0], model.metrics_names[1], scores[1]*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss of 0.0189112089574337; accuracy of 100.0%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "imgs, labels = next(test_batches)\n",
    "model = keras.models.load_model(r\"sign_model.h5\")\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print('{0} of {1}; {2} of {3}%'\n",
    ".format(model.metrics_names[0], scores[0], model.metrics_names[1], scores[1]*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss of 0.3421238958835602; accuracy of 89.99999761581421%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 413,443\n",
      "Trainable params: 413,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "imgs, labels = next(test_batches) \n",
    "\n",
    "word_dict = {0:'One', 1:'Two', 2:'Three'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "\n",
    "print(\"Predicted labels\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)])\n",
    "    \n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted labels\n",
      "Two\n",
      "Two\n",
      "One\n",
      "Two\n",
      "Three\n",
      "Three\n",
      "Three\n",
      "Three\n",
      "One\n",
      "One\n",
      "Actual labels\n",
      "Two\n",
      "Two\n",
      "One\n",
      "Two\n",
      "Three\n",
      "Three\n",
      "Three\n",
      "Two\n",
      "One\n",
      "One\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit ('signLanguage': conda)"
  },
  "interpreter": {
   "hash": "dbefc7fec24977a464f4b9c177a97fefd575b7fc826e54ce789a21be2d4f3465"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
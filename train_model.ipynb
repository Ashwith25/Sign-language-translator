{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers.normalization import layer_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers.normalization import layer_normalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test image directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'D:\\gestures\\train'\n",
    "test_path = r'D:\\gestures\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 755 images belonging to 5 classes.\n",
      "Found 755 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "76/76 [==============================] - 5s 66ms/step - loss: 2.5785 - accuracy: 0.9086 - val_loss: 0.1983 - val_accuracy: 0.9404\n",
      "Epoch 2/100\n",
      "76/76 [==============================] - 3s 42ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9430\n",
      "Epoch 3/100\n",
      "76/76 [==============================] - 3s 43ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9417\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(5,activation =\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "history2 = model.fit(train_batches, epochs=100, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.578505039215088, 0.006435680203139782, 0.003241561120375991],\n",
       " 'accuracy': [0.9086092710494995, 1.0, 1.0],\n",
       " 'val_loss': [0.19825880229473114, 0.1998724788427353, 0.20020121335983276],\n",
       " 'val_accuracy': [0.940397322177887, 0.9430463314056396, 0.9417218565940857],\n",
       " 'lr': [0.001, 0.001, 0.0005]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history2.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: signModelNew\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('signModelNew')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 0.008135863579809666; accuracy of 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.008135863579809666, 1.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, labels = next(test_batches) \n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print('{0} of {1}; {2} of {3}%'\n",
    ".format(model.metrics_names[0], scores[0], model.metrics_names[1], scores[1]*100))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 0.024884339421987534; accuracy of 100.0%\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(test_batches)\n",
    "model = keras.models.load_model(\"signModelNew\")\n",
    "# new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print('{0} of {1}; {2} of {3}%'\n",
    ".format(model.metrics_names[0], scores[0], model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 413,701\n",
      "Trainable params: 413,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels\n",
      "One\n",
      "Two\n",
      "Two\n",
      "Three\n",
      "Three\n",
      "Three\n",
      "Little\n",
      "One\n",
      "Two\n",
      "One\n",
      "Actual labels\n",
      "One\n",
      "Two\n",
      "Two\n",
      "Three\n",
      "Three\n",
      "Three\n",
      "Little\n",
      "One\n",
      "Two\n",
      "One\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(test_batches) \n",
    "\n",
    "word_dict = {0:'One', 1:'Two', 2:'Three', 3:'I Love You', 4:'Little'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "print(\"Predicted labels\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)])\n",
    "    predicted_labels.append(word_dict[np.argmax(i)])\n",
    "    \n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)])\n",
    "    actual_labels.append(word_dict[np.argmax(i)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.9583333333333334\n",
      "Recall 0.8333333333333334\n",
      "f1_score 0.8666666666666666\n",
      "confusion_matrix: \n",
      "[[1 0 0]\n",
      " [0 1 1]\n",
      " [0 0 7]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Precision\", sk.metrics.precision_score(actual_labels, predicted_labels, average='macro'))\n",
    "print (\"Recall\", sk.metrics.recall_score(actual_labels, predicted_labels, average='macro'))\n",
    "print (\"f1_score\", sk.metrics.f1_score(actual_labels, predicted_labels, average='macro'))\n",
    "print (\"confusion_matrix: \")\n",
    "print (sk.metrics.confusion_matrix(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbefc7fec24977a464f4b9c177a97fefd575b7fc826e54ce789a21be2d4f3465"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('signLanguage': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

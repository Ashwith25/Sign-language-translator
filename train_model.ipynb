{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers.normalization import layer_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers.normalization import layer_normalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test image directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'D:\\gesture\\train'\n",
    "test_path = r'D:\\gesture\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 629 images belonging to 3 classes.\n",
      "Found 413 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(64,64), class_mode='categorical', batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 11s 157ms/step - loss: 1.8390 - accuracy: 0.8426 - val_loss: 0.4546 - val_accuracy: 0.7797\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0256 - accuracy: 0.9984 - val_loss: 0.2651 - val_accuracy: 0.9274\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9225\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9225\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9274\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9249\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9249\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9249\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(3,activation =\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "history2 = model.fit(train_batches, epochs=100, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.838985562324524,\n",
       "  0.025573257356882095,\n",
       "  0.009534615091979504,\n",
       "  0.005050939042121172,\n",
       "  0.0035314252600073814,\n",
       "  0.0026788455434143543,\n",
       "  0.0021481155417859554,\n",
       "  0.0018230680143460631],\n",
       " 'accuracy': [0.842607319355011,\n",
       "  0.998410165309906,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'val_loss': [0.45458319783210754,\n",
       "  0.2651228904724121,\n",
       "  0.24634303152561188,\n",
       "  0.24308721721172333,\n",
       "  0.24192912876605988,\n",
       "  0.2416483759880066,\n",
       "  0.24252155423164368,\n",
       "  0.24279923737049103],\n",
       " 'val_accuracy': [0.7796609997749329,\n",
       "  0.9273607730865479,\n",
       "  0.9225181341171265,\n",
       "  0.9225181341171265,\n",
       "  0.9273607730865479,\n",
       "  0.9249394536018372,\n",
       "  0.9249394536018372,\n",
       "  0.9249394536018372],\n",
       " 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history2.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: signModel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('signModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 0.10377870500087738; accuracy of 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10377870500087738, 1.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, labels = next(test_batches) \n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print('{0} of {1}; {2} of {3}%'\n",
    ".format(model.metrics_names[0], scores[0], model.metrics_names[1], scores[1]*100))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of 0.10839533805847168; accuracy of 89.99999761581421%\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(test_batches)\n",
    "model = keras.models.load_model(\"sign_model\")\n",
    "# new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print('{0} of {1}; {2} of {3}%'\n",
    ".format(model.metrics_names[0], scores[0], model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                294976    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 413,443\n",
      "Trainable params: 413,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels\n",
      "Two\n",
      "Two\n",
      "One\n",
      "Two\n",
      "Two\n",
      "Two\n",
      "Three\n",
      "Two\n",
      "Two\n",
      "Two\n",
      "Actual labels\n",
      "Three\n",
      "Two\n",
      "One\n",
      "Two\n",
      "Two\n",
      "Two\n",
      "Three\n",
      "Two\n",
      "Two\n",
      "Two\n"
     ]
    }
   ],
   "source": [
    "imgs, labels = next(test_batches) \n",
    "\n",
    "word_dict = {0:'One', 1:'Two', 2:'Three'}\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "print(\"Predicted labels\")\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)])\n",
    "    predicted_labels.append(word_dict[np.argmax(i)])\n",
    "    \n",
    "print('Actual labels')\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)])\n",
    "    actual_labels.append(word_dict[np.argmax(i)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.9583333333333334\n",
      "Recall 0.8333333333333334\n",
      "f1_score 0.8666666666666666\n",
      "confusion_matrix: \n",
      "[[1 0 0]\n",
      " [0 1 1]\n",
      " [0 0 7]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Precision\", sk.metrics.precision_score(actual_labels, predicted_labels, average='macro'))\n",
    "print (\"Recall\", sk.metrics.recall_score(actual_labels, predicted_labels, average='macro'))\n",
    "print (\"f1_score\", sk.metrics.f1_score(actual_labels, predicted_labels, average='macro'))\n",
    "print (\"confusion_matrix: \")\n",
    "print (sk.metrics.confusion_matrix(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbefc7fec24977a464f4b9c177a97fefd575b7fc826e54ce789a21be2d4f3465"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('signLanguage': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
